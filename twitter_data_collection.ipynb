{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up query on twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import Twython  \n",
    "import json\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:  \n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n",
    "\n",
    "# Create our query\n",
    "query = {'q': 'BJP',  \n",
    "        'result_type': 'popular',\n",
    "        'count': 10,\n",
    "        'lang': 'en',\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the search\n",
    "\n",
    "#### Note about search from twitter docs\n",
    "Before digging in, it’s important to know that the standard search API is focused on relevance and not completeness. This means that some Tweets and users may be missing from search results. If you want to match for completeness you should consider the premium or enterprise search APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Mar 19 06:52:03 +0000 2019</td>\n",
       "      <td>30016</td>\n",
       "      <td>BJP leaders must stop saying publicly that Ind...</td>\n",
       "      <td>Swamy39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue Mar 19 05:28:24 +0000 2019</td>\n",
       "      <td>17708</td>\n",
       "      <td>CMs picked by BJP\\n\\nDevendra Fadnavis: 48 yea...</td>\n",
       "      <td>Tejasvi_Surya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mon Mar 18 13:37:40 +0000 2019</td>\n",
       "      <td>7751</td>\n",
       "      <td>Rahul is transferring millions of votes via hi...</td>\n",
       "      <td>muglikar_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Mar 19 04:47:43 +0000 2019</td>\n",
       "      <td>5928</td>\n",
       "      <td>Out of BJP’s 12 incumbent chief ministers, fiv...</td>\n",
       "      <td>akhileshsharma1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Mar 18 17:18:08 +0000 2019</td>\n",
       "      <td>5461</td>\n",
       "      <td>Aaj Tak channel spots lone anti-BJP voice in a...</td>\n",
       "      <td>UnSubtleDesi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date  favorite_count  \\\n",
       "2  Tue Mar 19 06:52:03 +0000 2019           30016   \n",
       "0  Tue Mar 19 05:28:24 +0000 2019           17708   \n",
       "5  Mon Mar 18 13:37:40 +0000 2019            7751   \n",
       "4  Tue Mar 19 04:47:43 +0000 2019            5928   \n",
       "3  Mon Mar 18 17:18:08 +0000 2019            5461   \n",
       "\n",
       "                                                text             user  \n",
       "2  BJP leaders must stop saying publicly that Ind...          Swamy39  \n",
       "0  CMs picked by BJP\\n\\nDevendra Fadnavis: 48 yea...    Tejasvi_Surya  \n",
       "5  Rahul is transferring millions of votes via hi...        muglikar_  \n",
       "4  Out of BJP’s 12 incumbent chief ministers, fiv...  akhileshsharma1  \n",
       "3  Aaj Tak channel spots lone anti-BJP voice in a...     UnSubtleDesi  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}  \n",
    "for status in python_tweets.search(**query)['statuses']:  \n",
    "    dict_['user'].append(status['user']['screen_name'])\n",
    "    dict_['date'].append(status['created_at'])\n",
    "    dict_['text'].append(status['text'])\n",
    "    dict_['favorite_count'].append(status['favorite_count'])\n",
    "\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(dict_)  \n",
    "df.sort_values(by='favorite_count', inplace=True, ascending=False)  \n",
    "df.head(5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the Streaming API\n",
    "\n",
    "Collect Data into csv as and when twitter sends\n",
    "\n",
    "For fields you may want to filter on, check out https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer  \n",
    "import csv\n",
    "\n",
    "# Filter out unwanted data\n",
    "def process_tweet(tweet):  \n",
    "    d = {}\n",
    "    d['hashtags'] = [hashtag['text'] for hashtag in tweet['entities']['hashtags']]\n",
    "    d['text'] = tweet['text']\n",
    "    d['user'] = tweet['user']['screen_name']\n",
    "    d['user_loc'] = tweet['user']['location']\n",
    "    return d\n",
    "\n",
    "\n",
    "# Create a class that inherits TwythonStreamer\n",
    "class MyVanillaStreamer(TwythonStreamer):     \n",
    "\n",
    "    # Received data\n",
    "    def on_success(self, data):\n",
    "\n",
    "        # Only collect tweets in English\n",
    "        if data['lang'] == 'en':\n",
    "            tweet_data = process_tweet(data)\n",
    "            self.save_to_csv(tweet_data)\n",
    "\n",
    "    # Problem with the API\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "        self.disconnect()\n",
    "\n",
    "    # Save each tweet to csv file\n",
    "    def save_to_csv(self, tweet):\n",
    "        with open(r'saved_tweets.csv', 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(list(tweet.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer  \n",
    "import csv\n",
    "\n",
    "# Filter out unwanted data\n",
    "def process_tweet(tweet):  \n",
    "    ## bypassing the processing\n",
    "    # return tweet\n",
    "    d = {}  \n",
    "    d['hashtags'] = [hashtag['text'] for hashtag in tweet['entities']['hashtags']]\n",
    "    d['text'] = tweet['text']\n",
    "    d['user'] = tweet['user']['screen_name']\n",
    "    d['user_loc'] = tweet['user']['location']\n",
    "    return d\n",
    "\n",
    "\n",
    "# Create a class that inherits TwythonStreamer\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    # csv_counter\n",
    "    csv_counter = 0\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.keyword = ''\n",
    "        \n",
    "        if 'tweet_count' in kwargs:\n",
    "            self.tweet_count = kwargs.pop('tweet_count')\n",
    "        if 'csv_name' in kwargs:\n",
    "            self.csv_name = kwargs.pop('csv_name')\n",
    "        else:\n",
    "            MyStreamer.csv_counter += 1\n",
    "            self.csv_name = 'saved_tweets_'+str(MyStreamer.csv_counter)\n",
    "        super().__init__(*args, **kwargs)\n",
    "            \n",
    "    # Received data\n",
    "    def on_success(self, data):\n",
    "        if self.tweet_count <= 0:\n",
    "            self.disconnect()\n",
    "        # Only collect tweets in English\n",
    "        if data['lang'] == 'en':\n",
    "            tweet_data = process_tweet(data)\n",
    "            self.save_to_csv(tweet_data)\n",
    "            self.tweet_count -= 1\n",
    "\n",
    "            \n",
    "\n",
    "    # Problem with the API\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "        self.disconnect()\n",
    "\n",
    "    # Save each tweet to csv file\n",
    "    def save_to_csv(self, tweet):\n",
    "        with open(self.csv_name + '_'+ self.keyword + r'.csv', 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(list(tweet.values()))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "\n",
    "Must find way to gracefully interrupt streaming  \n",
    "Real time may be necessary or not - depending on if we want trends. Twitter has an api to filter trends based on location - but IDK if twython has bindings to it or we have to play around with requests  \n",
    "Trends may be found in a different way to - needs to be explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modded\n",
    "# Instantiate from our streaming class\n",
    "stream = MyStreamer(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'],  \n",
    "                    creds['ACCESS_TOKEN'], creds['ACCESS_SECRET'], tweet_count = 100, csv_name = 'election_data')\n",
    "# Start the stream\n",
    "# specify the keyword to be tracked\n",
    "stream.keyword = 'BJP'\n",
    "stream.statuses.filter(track=stream.keyword)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7b8ddb90c4ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# specify the keyword to be tracked\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'BJP'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mvanilla_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatuses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/arjunil/anaconda3/lib/python3.5/site-packages/twython/streaming/types.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://stream.twitter.com/%s/statuses/filter.json'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m               \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/arjunil/anaconda3/lib/python3.5/site-packages/twython/streaming/api.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, url, method, params)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry_counter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/arjunil/anaconda3/lib/python3.5/site-packages/requests/models.py\u001b[0m in \u001b[0;36miter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    745\u001b[0m         \u001b[0mpending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_unicode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_unicode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpending\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/arjunil/anaconda3/lib/python3.5/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/arjunil/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \"\"\"\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/arjunil/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    592\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m                 \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m                 decoded = self._decode(chunk, decode_content=decode_content,\n\u001b[0m\u001b[0;32m    595\u001b[0m                                        flush_decoder=False)\n\u001b[0;32m    596\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "# Instantiate from our streaming class\n",
    "vanilla_stream = MyVanillaStreamer(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'],  \n",
    "                    creds['ACCESS_TOKEN'], creds['ACCESS_SECRET'])\n",
    "# Start the stream\n",
    "# specify the keyword to be tracked\n",
    "keyword = 'BJP'\n",
    "vanilla_stream.statuses.filter(track=keyword)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT @plittooo: #ChowkidaarNahiJawabdarChahiye\n",
       "\n",
       "Tribute to our 1st Prime Minister Pt. Jawaharlal Nehru Ji🙏🙏.\n",
       "\n",
       "Past 5 years of BJP is summed u…</th>\n",
       "      <th>Aazaad_India</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>['ChowkidaarNahiJawabdarChahiye']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @abpnewstv: #LokSabhaElections2019 : Chhatt...</td>\n",
       "      <td>AdityaJha93</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>['LokSabhaElections2019', 'BJP']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @kanimozhi: Twitter directly campaigning fo...</td>\n",
       "      <td>v_jai_ho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['CambridgeAnalytica']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cong-JDS to campaign jointly, vow to reduce BJ...</td>\n",
       "      <td>State_Times</td>\n",
       "      <td>Jammu | Kashmir | Delhi</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @OnlyNakedTruth: Ok folks , time to call Ra...</td>\n",
       "      <td>always_salil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @thenglishpost: #EC notice, police complain...</td>\n",
       "      <td>onlynishank</td>\n",
       "      <td>India</td>\n",
       "      <td>['EC', 'BJP', 'LokSabhaElections2019']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RT @plittooo: #ChowkidaarNahiJawabdarChahiye\\n\\nTribute to our 1st Prime Minister Pt. Jawaharlal Nehru Ji🙏🙏.\\n\\nPast 5 years of BJP is summed u…  \\\n",
       "0  RT @abpnewstv: #LokSabhaElections2019 : Chhatt...                                                                                                 \n",
       "1  RT @kanimozhi: Twitter directly campaigning fo...                                                                                                 \n",
       "2  Cong-JDS to campaign jointly, vow to reduce BJ...                                                                                                 \n",
       "3  RT @OnlyNakedTruth: Ok folks , time to call Ra...                                                                                                 \n",
       "4  RT @thenglishpost: #EC notice, police complain...                                                                                                 \n",
       "\n",
       "   Aazaad_India               Unnamed: 2  \\\n",
       "0   AdityaJha93         New Delhi, India   \n",
       "1      v_jai_ho                      NaN   \n",
       "2   State_Times  Jammu | Kashmir | Delhi   \n",
       "3  always_salil                      NaN   \n",
       "4   onlynishank                    India   \n",
       "\n",
       "        ['ChowkidaarNahiJawabdarChahiye']  \n",
       "0        ['LokSabhaElections2019', 'BJP']  \n",
       "1                  ['CambridgeAnalytica']  \n",
       "2                                      []  \n",
       "3                                      []  \n",
       "4  ['EC', 'BJP', 'LokSabhaElections2019']  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = 'saved_tweets_2.csv'\n",
    "tweets = pd.read_csv(file_name)\n",
    "\n",
    "tweets.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
